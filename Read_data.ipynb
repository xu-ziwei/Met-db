{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'stacked_image' at 0x21461224100>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Read all images\n",
    "images = [cv2.imread(f\"Metsys Data/44/Acquire_0/25/0/{i}.bmp\",cv2.IMREAD_GRAYSCALE) for i in range(20)]\n",
    "\n",
    "# Stack all images vertically\n",
    "stacked_image = np.array(images)\n",
    "\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(stacked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT for registration\n",
    "* Image Loading\n",
    "* Laplacian Variance Function:\n",
    "    * Purpose: To evaluate the sharpness or focus measure of an image\n",
    "* Computing Relative Shifts:\n",
    "    * Computes 2D Fast Fourier Transforms (FFTs) of two consecutive images.\n",
    "    * Calculates the normalized cross-power spectrum\n",
    "    * Detects the shift by identifying the position of maximum correlation in the spatial domain.\n",
    "    * Adjusts the detected shift to handle the FFT's wraparound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [cv2.imread(f\"Metsys Data/44/Acquire_0/25/0/{i}.bmp\",cv2.IMREAD_GRAYSCALE) for i in range(20)]\n",
    "\n",
    "\n",
    "def laplacian_variance(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "# Compute the relative shifts\n",
    "shifts = [(0, 0)]\n",
    "for i in range(1, len(images)):\n",
    "    dft_A = np.fft.fft2(images[i-1])\n",
    "    dft_B = np.fft.fft2(images[i])\n",
    "    \n",
    "    cross_power = dft_A * np.conj(dft_B)\n",
    "    R = cross_power / np.abs(cross_power)\n",
    "    \n",
    "    shift = np.unravel_index(np.argmax(np.fft.ifft2(R).real), images[i].shape)\n",
    "    \n",
    "    # Convert to relative shift (taking care of the wraparound from FFT)\n",
    "    shift = (shift[0] if shift[0] <= images[i].shape[0] // 2 else shift[0] - images[i].shape[0],\n",
    "             shift[1] if shift[1] <= images[i].shape[1] // 2 else shift[1] - images[i].shape[1])\n",
    "    \n",
    "    shifts.append(shift)\n",
    "\n",
    "max_shift_x = int(max([shift[1] for shift in shifts]))\n",
    "max_shift_y = int(max([shift[0] for shift in shifts]))\n",
    "\n",
    "panorama_width = images[0].shape[1] + max_shift_x * len(images)\n",
    "panorama_height = images[0].shape[0] + max_shift_y * len(images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack\n",
    "* make an stack by shifts list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_image = np.zeros((20, panorama_height, panorama_width))\n",
    "\n",
    "z = 0\n",
    "y = 0 \n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "for img, (y_shift, _) in zip(images, shifts):\n",
    "    size_y, size_x = img.shape\n",
    "    y += y_shift\n",
    "    y_start = y\n",
    "    y_end = y + size_y\n",
    "    plane_image[z, y_start: y_end, :] = images[z]\n",
    "    \n",
    "    z += 1  # Increment z for the next image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take the shift_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_s = 0\n",
    "for i in range(20):\n",
    "    shift_s += shifts[i][0]\n",
    "shift_m = int(shift_s/19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_image_shift_m = np.zeros((20, panorama_height, panorama_width))\n",
    "\n",
    "z = 0\n",
    "y = 0 \n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "for img in images:\n",
    "    size_y, size_x = img.shape\n",
    "    if z==0:\n",
    "        y=0\n",
    "    else:\n",
    "        y += shift_m\n",
    "    y_start = y\n",
    "    y_end = y + size_y\n",
    "    plane_image_shift_m[z, y_start: y_end, :] = images[z]\n",
    "    z = z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image' at 0x214009d8220>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(plane_image.astype('uint8'))\n",
    "#viewer.add_image(plane_image_shift_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the canvas\n",
    "canvas = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "\n",
    "# Starting position for placing images\n",
    "x_offset = 0\n",
    "y_offset = 0\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Get the shift offset\n",
    "    y_offset += shifts[i][0]\n",
    "    if i != 0:\n",
    "        overlap_start = y_offset    \n",
    "        overlap_end = y_offset + img.shape[0] - shifts[i][0]# No overlap for the first image\n",
    "        for y in range(img.shape[0]):\n",
    "            for x in range(img.shape[1]):\n",
    "                canvas_y = y + y_offset\n",
    "                if overlap_start <= canvas_y <= overlap_end and canvas[canvas_y, x] != 0:\n",
    "                    # Calculate the weight for blending\n",
    "                    alpha = (canvas_y - overlap_start) / (overlap_end - overlap_start) # 0 to 1\n",
    "                    canvas[canvas_y, x] = (1-alpha) * canvas[canvas_y, x] + (alpha) * img[y, x]\n",
    "                else:\n",
    "                        canvas[canvas_y, x + x_offset] = img[y, x]\n",
    "    else:\n",
    "        # For the first image\n",
    "        canvas[0: img.shape[0], :] = images[0]\n",
    "\n",
    "plane_image_alpha = canvas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### time efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "\n",
    "\n",
    "x_offset = 0 \n",
    "y_offset = 0\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Determine overlap regions\n",
    "    overlap_start = y_offset + shifts[i][0]\n",
    "    overlap_end = y_offset + img.shape[0]\n",
    "\n",
    "    overlap = canvas[overlap_start:overlap_end, :]\n",
    "\n",
    "\n",
    "    if i != 0 and np.any(overlap):\n",
    "        # create an alpha mask\n",
    "        mask = np.linspace(1, 0, overlap.shape[0])[np.newaxis, :].T\n",
    "        mask = np.repeat(mask, overlap.shape[1], axis=1)\n",
    "        \n",
    "        # Apply the mask for blending\n",
    "        foreground = cv2.multiply(mask, overlap.astype(float))\n",
    "        background = cv2.multiply(1.0 - mask, img[:overlap.shape[0]].astype(float))\n",
    "\n",
    "        blended = cv2.add(foreground, background).astype(np.uint8)\n",
    "\n",
    "        canvas[overlap_start:overlap_end, :] = blended\n",
    "        canvas[overlap_end:overlap_end + shifts[i][0], :] = img[overlap.shape[0]:, :]\n",
    "    else:\n",
    "        # for first image\n",
    "        canvas[0:overlap_end, :] = img\n",
    "    \n",
    "    y_offset += shifts[i][0]\n",
    "\n",
    "plane_image_alpha2 = canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'plane_image_alpha2' at 0x1ca57ab6640>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(stacked_image)\n",
    "viewer.add_image(plane_image.astype('uint8'))\n",
    "#viewer.add_image(plane_image_alpha)\n",
    "viewer.add_image(plane_image_alpha2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiband Blending\n",
    "\n",
    "* Build Laplacian pyramids $L1$ and $L2$ from images 1 and 2\n",
    "* Build a Gaussian pyramid $GM$ from selection mask M\n",
    "* Form a combined pyramid $LS$ from $L1$ and $L2$ using $GM$ as weights:\n",
    "    * $LS = GM * L1 + (1-GM) * L2$\n",
    "* Collapse the $LS$ pyramid to get the final blended image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gaussian and Laplacian pyramids\n",
    "def build_gaussian_pyramid(img, levels):\n",
    "    pyramid = [img]\n",
    "    for i in range(levels - 1):\n",
    "        img = cv2.pyrDown(img)\n",
    "        pyramid.append(img)\n",
    "    return pyramid\n",
    "\n",
    "def build_laplacian_pyramid(img, levels):\n",
    "    gaussian_pyramid = build_gaussian_pyramid(img, levels)\n",
    "    laplacian_pyramid = []\n",
    "    for i in range(levels - 1):\n",
    "        size = (gaussian_pyramid[i].shape[1], gaussian_pyramid[i].shape[0])\n",
    "        expanded = cv2.pyrUp(gaussian_pyramid[i + 1], dstsize=size)\n",
    "        laplacian = cv2.subtract(gaussian_pyramid[i], expanded)\n",
    "        laplacian_pyramid.append(laplacian)\n",
    "    laplacian_pyramid.append(gaussian_pyramid[-1])  # Add the smallest level as it is\n",
    "    return laplacian_pyramid\n",
    "    \n",
    "# Blend two images using Gaussian pyramids\n",
    "def blend_images(img1, img2, mask, levels):\n",
    "    # Generate pyramids\n",
    "    LP_img1 = build_laplacian_pyramid(img1, levels)\n",
    "    LP_img2 = build_laplacian_pyramid(img2, levels)\n",
    "    GP_mask = build_gaussian_pyramid(mask, levels)\n",
    "\n",
    "    # Blend\n",
    "    blended_pyramid = []\n",
    "    for l_img1, l_img2, g_mask in zip(LP_img1, LP_img2, GP_mask):\n",
    "        blended_pyramid.append(l_img1 * g_mask + l_img2 * (1.0 - g_mask))\n",
    "    \n",
    "    # Reconstruct\n",
    "    reconstructed_image = blended_pyramid[-1]\n",
    "    for i in range(len(blended_pyramid)-2, -1, -1):\n",
    "        size = (blended_pyramid[i].shape[1], blended_pyramid[i].shape[0])\n",
    "        upsampled = cv2.pyrUp(reconstructed_image, dstsize=size)\n",
    "        reconstructed_image = cv2.add(upsampled, blended_pyramid[i])\n",
    "\n",
    "    return reconstructed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "\n",
    "#set pyramid level\n",
    "level = 2\n",
    "\n",
    "x_offset = 0  # Assuming vertical stacking of images\n",
    "y_offset = 0\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Determine overlap regions\n",
    "    overlap_start = y_offset + shifts[i][0]\n",
    "    overlap_end = y_offset + img.shape[0]\n",
    "\n",
    "    overlap = canvas[overlap_start:overlap_end, :]\n",
    "\n",
    "\n",
    "    if i != 0 and np.any(overlap):\n",
    "        mask = np.ones(overlap.shape)\n",
    "\n",
    "        # Only blending the overlap region of the canvas (which includes the previous image) and the current image.\n",
    "        blended = blend_images(overlap, img[0:img.shape[0]-shifts[i][0]], mask, level)\n",
    "       \n",
    "        canvas[overlap_start:overlap_end, :] = blended\n",
    "        canvas[overlap_end:overlap_end + shifts[i][0], :] = img[overlap.shape[0]:, :]\n",
    "    else:\n",
    "        # for first image\n",
    "        canvas[0:overlap_end, :] = img\n",
    "    \n",
    "    y_offset += shifts[i][0]\n",
    "\n",
    "    plane_image_MBB = canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'stacked_image' at 0x217a3d6ef70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(plane_image.astype('uint8'))\n",
    "viewer.add_image(plane_image_alpha2)\n",
    "viewer.add_image(plane_image_MBB)\n",
    "viewer.add_image(stacked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_blend(source, target, mask, offset):\n",
    "    # Compute the region to be blended\n",
    "    y_min, y_max, x_min, x_max = compute_bounding_box(mask, offset)\n",
    "\n",
    "    # Extract regions from source, target, and mask images\n",
    "    source_region = source[y_min:y_max, x_min:x_max]\n",
    "    target_region = target[y_min+offset[1]:y_max+offset[1], x_min+offset[0]:x_max+offset[0]]\n",
    "    mask_region = mask[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Compute the Laplacian of the source region\n",
    "    laplacian = cv2.Laplacian(source_region, cv2.CV_64F)\n",
    "\n",
    "    # Here, you'd typically solve the Poisson equation to get the blended region.\n",
    "    # This is a simplified approach:\n",
    "    for y in range(mask_region.shape[0]):\n",
    "        for x in range(mask_region.shape[1]):\n",
    "            if mask_region[y, x] == 255:  # Pixel is in the mask\n",
    "                target_region[y, x] += laplacian[y, x]\n",
    "\n",
    "    result = target.copy()\n",
    "    result[y_min+offset[1]:y_max+offset[1], x_min+offset[0]:x_max+offset[0]] = target_region\n",
    "    return result\n",
    "\n",
    "def compute_bounding_box(mask, offset):\n",
    "    y_indices, x_indices = np.where(mask == 255)\n",
    "    y_min = np.min(y_indices)\n",
    "    y_max = np.max(y_indices) + 1\n",
    "    x_min = np.min(x_indices)\n",
    "    x_max = np.max(x_indices) + 1\n",
    "    return y_min, y_max, x_min, x_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "\n",
    "x_offset = 0 \n",
    "y_offset = 0\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Determine overlap regions\n",
    "    overlap_start = y_offset + shifts[i][0]\n",
    "    overlap_end = y_offset + img.shape[0]\n",
    "\n",
    "    overlap = canvas[overlap_start:overlap_end, :]\n",
    "    \n",
    "    if i != 0:  # Not the first image\n",
    "        # Create a binary mask for Poisson blending. Assuming vertical blend, so overlap will be full width.\n",
    "        mask = np.zeros_like(img, dtype=np.uint8)\n",
    "        mask[:overlap_end - overlap_start, :] = 255  # White region for blending\n",
    "\n",
    "        # Use Poisson blending\n",
    "        blended = poisson_blend(img, canvas, mask, (x_offset, overlap_start))\n",
    "        canvas[overlap_start:overlap_end, :] = blended[overlap_start:overlap_end, :]\n",
    "        canvas[overlap_end:overlap_end + shifts[i][0], :] = img[overlap.shape[0]:, :]\n",
    "    else:\n",
    "        # For the first image, just place it on the canvas.\n",
    "        canvas[0:overlap_end, :] = img\n",
    "    \n",
    "    y_offset += shifts[i][0]\n",
    "\n",
    "plane_image_poisson = canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img min-max: 13 255\n",
      "canvas min-max: 0 255\n",
      "mask min-max: 0 255\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\deriv.cpp:792: error: (-215:Assertion failed) !_src.empty() in function 'cv::Laplacian'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\Metsys\\Read_data.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Metsys/Read_data.ipynb#X60sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmask min-max:\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mmin(mask), np\u001b[39m.\u001b[39mmax(mask))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Metsys/Read_data.ipynb#X60sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Use cv2.seamlessClone\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Metsys/Read_data.ipynb#X60sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     canvas \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mseamlessClone(img, canvas, mask, center, cv2\u001b[39m.\u001b[39;49mNORMAL_CLONE)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Metsys/Read_data.ipynb#X60sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Metsys/Read_data.ipynb#X60sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# For the first image, just place it on the canvas.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Metsys/Read_data.ipynb#X60sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     canvas[\u001b[39m0\u001b[39m:overlap_end, :] \u001b[39m=\u001b[39m img\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\deriv.cpp:792: error: (-215:Assertion failed) !_src.empty() in function 'cv::Laplacian'\n"
     ]
    }
   ],
   "source": [
    "x_offset = 0 \n",
    "y_offset = 0\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Determine overlap regions\n",
    "    overlap_start = y_offset + shifts[i][0]\n",
    "    overlap_end = y_offset + img.shape[0]\n",
    "    if i != 0:\n",
    "    # Create the mask\n",
    "        mask = np.zeros(img.shape, dtype=np.uint8)\n",
    "        mask[:overlap_end - overlap_start, :] = 255\n",
    "\n",
    "        # Determine center of the overlapping region for seamless cloning\n",
    "        center_x = int(img.shape[1] // 2)\n",
    "        center_y = int((overlap_start + overlap_end) // 2)\n",
    "        center = (center_x, center_y + y_offset)\n",
    "        print(\"img min-max:\", np.min(img), np.max(img))\n",
    "        print(\"canvas min-max:\", np.min(canvas), np.max(canvas))\n",
    "        print(\"mask min-max:\", np.min(mask), np.max(mask))\n",
    "\n",
    "    # Use cv2.seamlessClone\n",
    "        canvas = cv2.seamlessClone(img, canvas, mask, center, cv2.NORMAL_CLONE)\n",
    "    else:\n",
    "        # For the first image, just place it on the canvas.\n",
    "        canvas[0:overlap_end, :] = img\n",
    "    \n",
    "    y_offset += shifts[i][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\deriv.cpp:792: error: (-215:Assertion failed) !_src.empty() in function 'cv::Laplacian'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_img = np.ones((1920, 2560), dtype=np.uint8) * 255\n",
    "dummy_canvas = np.zeros((4380, 2560), dtype=np.uint8)\n",
    "dummy_mask = np.ones((1920, 2560), dtype=np.uint8) * 255\n",
    "dummy_center = (1280, 1019)\n",
    "\n",
    "try:\n",
    "    result = cv2.seamlessClone(dummy_img, dummy_canvas, dummy_mask, dummy_center, cv2.NORMAL_CLONE)\n",
    "    cv2.imshow(\"Result\", result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_end - overlap_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'plane_image_poisson' at 0x1ca0eebab80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "#viewer.add_image(plane_image.astype('uint8'))\n",
    "viewer.add_image(plane_image_poisson)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PoissonBlending import blend\n",
    "\n",
    "canvas = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "\n",
    "x_offset = 0 \n",
    "y_offset = 0\n",
    "\n",
    "for i, img in enumerate(images):\n",
    "    # Determine overlap regions\n",
    "    overlap_start = y_offset + shifts[i][0]\n",
    "    overlap_end = y_offset + img.shape[0]\n",
    "\n",
    "    if i != 0:\n",
    "        # Determine the mask for Poisson blending\n",
    "        mask = np.zeros_like(img, dtype=np.uint8)\n",
    "        mask[:overlap.shape[0], :] = 255  # this mask will be used to blend the overlapping region\n",
    "\n",
    "        # Apply Poisson blending\n",
    "        offset = (0, overlap_start)\n",
    "        canvas = blend(canvas, img, mask, offset)\n",
    "    else:\n",
    "        # For the first image\n",
    "        canvas[0:overlap_end, :] = img\n",
    "\n",
    "    y_offset += shifts[i][0]\n",
    "\n",
    "plane_image_alpha2 = canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 2560)\n",
      "(1801, 2560)\n",
      "(1800, 2560)\n",
      "(1797, 2560)\n",
      "(1797, 2560)\n",
      "(1798, 2560)\n",
      "(1799, 2560)\n",
      "(1800, 2560)\n",
      "(1798, 2560)\n",
      "(1800, 2560)\n",
      "(1799, 2560)\n",
      "(1800, 2560)\n",
      "(1800, 2560)\n",
      "(1798, 2560)\n",
      "(1798, 2560)\n",
      "(1800, 2560)\n",
      "(1800, 2560)\n",
      "(1800, 2560)\n",
      "(1799, 2560)\n",
      "(1802, 2560)\n"
     ]
    }
   ],
   "source": [
    "for i, img in enumerate(images):\n",
    "    # Determine overlap regions\n",
    "    overlap_start = y_offset + shifts[i][0]\n",
    "    overlap_end = y_offset + img.shape[0]\n",
    "    overlap = canvas[overlap_start:overlap_end, :]\n",
    "    print(overlap.shape)\n",
    "    y_offset += shifts[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.ones(overlap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros((panorama_height, panorama_width), dtype=np.uint8)\n",
    "img = images[0]\n",
    "\n",
    "canvas[0:1920,:]=img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1801, 2560)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "img1 = images[0]\n",
    "img = images[i]\n",
    "\n",
    "y_offset = 0\n",
    "\n",
    "overlap_start = y_offset + shifts[i][0]\n",
    "overlap_end = y_offset + img.shape[0]\n",
    "overlap = canvas[overlap_start:overlap_end, :]\n",
    "\n",
    "\n",
    "if i != 0 and np.any(overlap):\n",
    "        mask = np.ones(overlap.shape)\n",
    "        print(mask.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1801, 2560) (1801, 2560) (1801, 2560)\n",
      "(901, 1280) (901, 1280) (901, 1280)\n",
      "(451, 640) (451, 640) (451, 640)\n",
      "(226, 320) (226, 320) (226, 320)\n"
     ]
    }
   ],
   "source": [
    "blended_pyramid = []\n",
    "for l_img1, l_img2, g_mask in zip(LP_img1, LP_img2, GP_mask):\n",
    "    print(l_img1.shape,l_img2.shape,g_mask.shape)\n",
    "    blended_pyramid.append(l_img1 * g_mask + l_img2 * (1.0 - g_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image = blended_pyramid[-1]\n",
    "for i in range(len(blended_pyramid)-2, -1, -1):\n",
    "    size = (blended_pyramid[i].shape[1], blended_pyramid[i].shape[0])\n",
    "    upsampled = cv2.pyrUp(reconstructed_image, dstsize=size)\n",
    "    reconstructed_image = cv2.add(upsampled, blended_pyramid[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'reconstructed_image' at 0x27900960250>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(overlap)\n",
    "viewer.add_image(img1)\n",
    "viewer.add_image(reconstructed_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
